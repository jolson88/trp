- There are some interesting parallels around [[Advantages of Simplicity]] between building software and manufacturing
	- Realized while watching documentary on https://www.youtube.com/watch?v=3aeSBXO9waA (Haribo Gummies)
		- By focusing on one product (really, one "family" of products) with very simple ingredients, a lot of attention can go into economies of scale, specialized automation, expertise, etc.
- [[Can the transition between non-deterministic systems to deterministic behavior be understood?]]
	- There is a similarity between "classical coding" (deterministic) and "AI coding" (non-deterministic/probablistic) and physics with classical physics (deterministic) and quantum physics (non-deterministic)
		- Ongoing challenge to try to unify the two via quantum gravity, but has largely remained intractable
		- There's a decent "information gap" around the transition from non-determinism in the micro scale to our deterministic world in the macro world. When does it happen? Why? What is an "observer" (ala the observer problem)
		- There are also gaps between each layer of systems. We have models we've developed to largely deterministically predict the behavior of systems at different scales. The movement of particles, to the movement of fluids (where particles are too numerous to count or apply our lower-level understand and we have higher "estimations" of the behavior like navier stokes for fluids), etc.
	- Was thinking about this while watching a video about how diffusion is used to generative images and videos in new AI models: https://www.youtube.com/watch?v=iv-5mZ_9CPY
		- Started thinking about how the difference between AI coding and procedural coding is quite similar in nature (as regards to determinism) to quantum mechanics and classical physics. Especially the struggle of connecting the classical to the quantum and the various attempt at quantum gravity.
	- ChatGPT mentioned the relationship to "[[The Measurement Problem]]" in Physics:
		- "This refers to **how the deterministic world emerges from probabilistic quantum mechanics**, which is exactly the analogy you're making with AI.
			- **[[Quantum Decoherence]]**: Explains how quantum superpositions seem to “collapse” into classical states when interacting with an environment (e.g. observation).
			- Still **doesn't explain why only one outcome is observed** — the “observer problem.”
			- This is sometimes called the **"quantum-to-classical transition"**, and it's an ongoing area of research.
	- ChatGPT also mentioned "[[The Tower of Effective Theories]]" from physics. It's an interesting analogy and makes me think about how there's understanding when developing software that runs on a single machine in a single process, less about parallelism on a single machine, and even less of a large distributed system comprising many computers and systems. Here's what ChatGPT mentions:
		- [[The Tower of Effective Theories]]
			- This is a **framing device in physics** that describes how each level of physical description is an _“effective theory”_ at a given scale:
				- **Effective Field Theory (EFT)**: You don't need to know quantum chromodynamics to solve a thermodynamics problem — each layer has its own laws.
				- Yet, how these layers connect is often **not fully understood or derivable**.
				- This is similar to how we don't know how "fluid dynamics" _emerges_ precisely from Newtonian particles.
			- This concept is sometimes referred to as:
				- **Renormalization group theory**: Describes how physical laws "flow" as you change scales.
				- The **“reduction problem”** in philosophy of science.
- [[What is the Reduction Problem?]]
	- From ChatGPT:
		- TODO
- [[Are distributed systems in computing naturally a chaotic system?]]
	- Do small changes in initial conditions result in large differences in results?
	- Is long-term behavior practically unpredictable?
		- Is there a way to build the foundational pieces (or code the rules) to optimize how chaotic the system is in response to initial inputs?
	- _“Chaos is when the present determines the future, but the approximate present does not approximately determine the future.”_ — Edward Lorenz
- Interesting to think about [[Duality of Reductionism and Emergence]]. We often drive scientifically deeper via a reductionism process. But most larger systems behavior is emergent and so we try to derive observational-based models that can explain emergent behavior in a seemingly deterministic way.
	- There's a tension here between these. Reductionism vs. Complexity Theory. Reductionism vs. Computation Irreducability (though computational irreducability is perhaps better described as a constrain for reductionism akin to "as simple as possible, but no simpler" (how do you know "no simpler" line?)
- [[Can constraints be used on non-deterministic system output to compute deterministic results?]]
	- Can you use constraint solvers on AI output to build a deterministic system?
- [[What are Strange Loops?]]
	- From ChatGPT: "Hofstadter’s idea of **“strange loops”** in _Gödel, Escher, Bach_ is particularly close to your concept — **loops that rise upward through systems while feeding back into themselves**" 
	- Similar:
		- [[Spiral Dynamics]] (Psychology/Sociology): models developmental progression through recursive cycles
		- [[The Spiral of Understanding]] (Philosophy of Science (e.g. Gadamer, Polanyi)) — deeper understanding through iterative abstraction
		- [[Epicycles of Abstraction]] (Systems Theory): each layer simplifies the previous but introduces its own complexity